{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "# Índice\n",
    "* [Scraping](../scraper/Web-scraping.ipynb)\n",
    "* [Limpieza y Feature engineering](../limpieza/Limpieza-y-exploracion-de-datos-no-estructurados-con-spark.ipynb)\n",
    "* [Modelado](#Modelado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "**Predecir precios de venta de casas en San Francisco**\n",
    "\n",
    "- Los **datos**: Zillow. Información de casas en diferentes zonas, el precio y fecha en que se vendieron y el precio que se puso en los anuncios.\n",
    "- Variable a predecir: **lastsoldprice**.\n",
    "- El dataset tbn incluye zestimate: el valor estimado de venta que calculó Zillow pero no lo vamos a tomar en cuenta.\n",
    "- Haremos un análisis exploratorio brevísimo, una regresión lineal y un bosque aleatorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T19:19:15.369067Z",
     "start_time": "2018-04-27T19:19:14.707156Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importamos librerías para trabajar\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(66) # Importante para hacer los resultados reproducibles!!!\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T19:20:09.839281Z",
     "start_time": "2018-04-27T19:20:09.804698Z"
    }
   },
   "outputs": [],
   "source": [
    "# Leemos el csv de datos\n",
    "sf = pd.read_csv('final_data.csv')\n",
    "sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos renglones y columnas\n",
    "sf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T19:20:10.241312Z",
     "start_time": "2018-04-27T19:20:10.184574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tiramos algunas columnas que no necesitaremos para modelar\n",
    "# info,z_address,usecode,zipcode: vamos a considerar sólo neighborhood para indicarnos dónde está la casa.\n",
    "# recordemos que zestimate es el valor estimado por Zillow. No lo queremos incluir en el modelo y tbn lo quitamos.\n",
    "sf.drop(sf.columns[[0, 2, 3, 15, 17, 18]], axis=1, inplace=True)\n",
    "sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T19:20:21.130015Z",
     "start_time": "2018-04-27T19:20:11.020507Z"
    }
   },
   "outputs": [],
   "source": [
    "sf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que la variable zindexvalue tiene comas! es texto!!! No puede entrar así al modelo. Casteamos\n",
    "sf['zindexvalue'] = sf['zindexvalue'].str.replace(',', '')\n",
    "sf['zindexvalue'] = sf['zindexvalue'].convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticos resumen de  variables numéricas\n",
    "sf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T19:20:22.109866Z",
     "start_time": "2018-04-27T19:20:21.131518Z"
    }
   },
   "outputs": [],
   "source": [
    "#Histogramas para ver qué hay en cada columna numérica\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "sf.hist(bins=50, figsize=(20,15))\n",
    "# Podemos guardar la gráfica en un .png para poder usarla en presentaciones o pdfs\n",
    "plt.savefig(\"attribute_histogram_plots\")\n",
    "plt.show()\n",
    "\n",
    "# Variables tienen diferente escala\n",
    "# Sesgo puede dificultar que los modelos funcionen; cosas con distribuciones normales funcionan mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenemos latitud y longitud. Podemos pintar un scatterplot tal cual\n",
    "sf.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.2)\n",
    "plt.savefig('map1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Podemos pintar puntos en relación con el precio, que es lo que queremos predecir\n",
    "sf.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4, figsize=(10,7),\n",
    "    c=\"lastsoldprice\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
    "    sharex=False)\n",
    "plt.savefig('map2.png')\n",
    "# OJO! Podemos tener mapas más bonitos con plotly y mapbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlaciones del lastsoldprice contra todo\n",
    "\n",
    "corr_matrix = sf.corr()\n",
    "corr_matrix[\"lastsoldprice\"].sort_values(ascending=False)\n",
    "\n",
    "# finishedsqft y número de bathrooms tienen corr positiva y grande con lastsoldprice\n",
    "# Hay corr negativa con yearbuilt pero chica\n",
    "# Entre más cercano a cero, menor correlación linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos las variables que se ven más correlacionadas con lastsoldprice y pintamos un scatterplot\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"lastsoldprice\", \"finishedsqft\", \"bathrooms\", \"zindexvalue\"]\n",
    "scatter_matrix(sf[attributes], figsize=(12, 8))\n",
    "plt.savefig('matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo que mejor se ve es lastsoldprice y finishedsqft\n",
    "sf.plot(kind=\"scatter\", x=\"finishedsqft\", y=\"lastsoldprice\", alpha=0.5)\n",
    "plt.savefig('scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OJO, cada casa tiene diferentes metros cuadradas. Casas más grandes seguro son más caras.\n",
    "# Para poder comparar diferentes casas, necesitamos normalizar: precios por metro cuadrado\n",
    "sf['price_per_sqft'] = sf['lastsoldprice']/sf['finishedsqft']\n",
    "corr_matrix = sf.corr()\n",
    "corr_matrix[\"lastsoldprice\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La variable nueva (price_per_sqft) no tiene muy buena correlación con la que queremos predecir (lastsoldprice)\n",
    "# Quizá si agrupamos por neighbourhood salgan mejor los modelos\n",
    "len(sf['neighborhood'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiene sentido que el precio por metro cuadrado varíe por zona\n",
    "# veamos cuántas casas hay por neighborhood\n",
    "freq = sf.groupby('neighborhood').count()['address']\n",
    "# Y veamos el precio promedio para cada una de ellas\n",
    "mean = sf.groupby('neighborhood').mean()['price_per_sqft']\n",
    "# creamos un dataset nuevo\n",
    "cluster = pd.concat([freq, mean], axis=1)\n",
    "cluster['neighborhood'] = cluster.index\n",
    "cluster.columns = ['freq', 'price_per_sqft','neighborhood']\n",
    "cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y veamos resumen de las variables\n",
    "cluster.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos la media de precios por metro cuadrado: 756.\n",
    "# Y observamos la media de casas en cada colonia: 123\n",
    "# Podemos dividir las casas en 4 grupos, considerando ambas variables por arriba y por abajo de la media.\n",
    "# Spoiler alert: en las baratas no sirve de mucho tener grupos diferenciados según el número de casas en cada colonia\n",
    "# Así que sólo hacemos 3 clusters:\n",
    "\n",
    "# Podemos hacer un primer cluster de casas baratas\n",
    "cluster1 = cluster[cluster.price_per_sqft < 756]\n",
    "cluster1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otro cluster de casas caras y en colonias con pocas casas\n",
    "cluster_temp = cluster[cluster.price_per_sqft >= 756]\n",
    "cluster2 = cluster_temp[cluster_temp.freq <123]\n",
    "cluster2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un tercero para casas caras en colonias con muchas casas\n",
    "cluster3 = cluster_temp[cluster_temp.freq >=123]\n",
    "cluster3.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para usar esos clusters, hay que agregar una columna indicando a cuál grupo pertenece cada casa\n",
    "def get_group(x):\n",
    "    if x in cluster1.index:\n",
    "        return 'low_price'\n",
    "    elif x in cluster2.index:\n",
    "        return 'high_price_low_freq'\n",
    "    else:\n",
    "        return 'high_price_high_freq'\n",
    "# cluster.index es la neighborhood\n",
    "# agregamos al dataset original el grupo, haciendo un apply de la función que acabamos de definir\n",
    "sf['group'] = sf.neighborhood.apply(get_group)\n",
    "sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En los clusters estamos incluyendo información de ubicación. Podemos matar columnas que ya no sirven:\n",
    "sf.drop(sf.columns[[0, 4, 6, 7, 8, 13]], axis=1, inplace=True)\n",
    "sf = sf[['bathrooms', 'bedrooms', 'finishedsqft', 'totalrooms', 'usecode', 'yearbuilt','zindexvalue', 'group', 'lastsoldprice']]\n",
    "sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seguimos teniendo columnas no numéricas: usecode y group\n",
    "# Son categóricas. Necesitamos tener indicadoras.\n",
    "# Dividimos en variables explicativas y variable a predecir\n",
    "X = sf[['bathrooms', 'bedrooms', 'finishedsqft', 'totalrooms', 'usecode', 'yearbuilt', \n",
    "         'zindexvalue', 'group']]\n",
    "Y = sf['lastsoldprice']\n",
    "\n",
    "# Usamos una función de pandas para sacar indicadoras y las agregamos al dataset\n",
    "n = pd.get_dummies(sf.group)\n",
    "X = pd.concat([X, n], axis=1)\n",
    "\n",
    "m = pd.get_dummies(sf.usecode)\n",
    "X = pd.concat([X, m], axis=1)\n",
    "\n",
    "# Tiramos las variables categóricas originales porque ya las cambiamos por indicadoras.\n",
    "drops = ['group', 'usecode']\n",
    "X.drop(drops, inplace=True, axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora sí a entrenar el modelo\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# dividimos en train y test, con 70%-30% para cada uno\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Ojo con la notación que permite asignar en 4 objetos el resultado de train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión lineal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R cuadrada: qué porciento de la variabilidad en Y se explica vía X\n",
    "y_pred = regressor.predict(X_test)\n",
    "print('R cuadrada\": %.4f' % regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qué tan cerca están las predicciones del valor real? raíz del error cuadrático medio\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse = mean_squared_error(y_pred, y_test)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print('El modelo hace predicciones que difieren a lo más %.4f del precio real' % lin_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En valor absoluto, qué tan lejos estamos en promedio?\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lin_mae = mean_absolute_error(y_pred, y_test)\n",
    "print('Las predicciones del modelo están, en promedio a %.4f del precio real' % lin_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora un random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "forest_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R cuadrada: qué porciento de la variabilidad en Y se explica vía X\n",
    "print('R cuadrada del random forest: %.4f' % forest_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest_reg.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print('El random forest hace predicciones que difieren a lo más %.4f del precio real' % forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es importante poder explicar el modelo.\n",
    "# En una regresión, los coeficientes dan sentido de la importancia. En un bosque aleatorio?\n",
    "\n",
    "feature_labels = np.array(['bathrooms', 'bedrooms', 'finishedsqft', 'totalrooms', 'yearbuilt', 'zindexvalue', \n",
    "                           'high_price_high_freq', 'high_price_low_freq', 'low_price', 'Apartment', 'Condominium', 'Cooperative', \n",
    "                          'Duplex', 'Miscellaneous', 'Mobile', 'MultiFamily2To4', 'MultiFamily5Plus', 'SingleFamily', \n",
    "                           'Townhouse'])\n",
    "importance = forest_reg.feature_importances_\n",
    "feature_indexes_by_importance = importance.argsort()\n",
    "for index in feature_indexes_by_importance:\n",
    "    print('{}-{:.2f}%'.format(feature_labels[index], (importance[index] *100.0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {
    "height": "234px",
    "width": "334px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
